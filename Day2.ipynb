{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "efd18cbe-861b-4f70-bc40-d5dc86f55f11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "events = spark.read.csv(\"/path/to/sample.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Basic operations\n",
    "events.select(\"event_type\", \"product_name\", \"price\").show(10)\n",
    "events.filter(\"price > 100\").count()\n",
    "events.groupBy(\"event_type\").count().show()\n",
    "top_brands = events.groupBy(\"brand\").count().orderBy(\"count\", ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b928cc8-41e5-489f-aade-26cb86835433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events = spark.read.csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv\", header=True, inferSchema=True)\n",
    "# Basic operations\n",
    "events.select(\"event_type\",\"category_id\",\"category_code\",\"price\").show(10)\n",
    "events.filter(\"price > 100\").count()\n",
    "events.groupBy(\"event_type\").count().show()\n",
    "events.orderBy(\"price\", ascending=False).show(10)\n",
    "top_brands = events.groupBy(\"brand\").count().orderBy(\"count\", ascending=False).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "721257e7-b11f-494c-8440-aab6e1ebc490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "events.write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct-export.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7dc828-395a-4f2a-83d1-ae562ffe1e5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "events.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct-export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97fe3ae9-f7dc-494c-af6d-a41261b77f6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events = spark.read.csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv\", header=True, inferSchema=True)\n",
    "# Basic operations\n",
    "events.select(\"event_type\",\"category_id\",\"category_code\",\"price\").show(10)\n",
    "events.filter(\"price > 100\").count()\n",
    "events.groupBy(\"event_type\").count().show()\n",
    "events.orderBy(\"price\", ascending=False).show(10)\n",
    "top_brands = events.groupBy(\"brand\").count().orderBy(\"count\", ascending=False).limit(5)\n",
    "\n",
    "events.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov-export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e952b88-9c60-4cfd-974f-dc2728f65686",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "events = spark.read.csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv\", header=True, inferSchema=True)\n",
    "# Basic operations\n",
    "events.select(\"event_type\",\"category_id\",\"category_code\",\"price\").show(10)\n",
    "events.filter(\"price > 100\").count()\n",
    "events.groupBy(\"event_type\").count().show()\n",
    "events.orderBy(\"price\", ascending=False).show(10)\n",
    "top_brands = events.groupBy(\"brand\").count().orderBy(\"count\", ascending=False).limit(5)\n",
    "\n",
    "# Top 5 products by revenue\n",
    "revenue = events.filter(F.col(\"event_type\") == \"purchase\") \\\n",
    "    .groupBy(\"product_id\", \"product_name\") \\\n",
    "    .agg(F.sum(\"price\").alias(\"revenue\")) \\\n",
    "    .orderBy(F.desc(\"revenue\")).limit(5)\n",
    "\n",
    "# Running total per user\n",
    "window = Window.partitionBy(\"user_id\").orderBy(\"event_time\")\n",
    "events.withColumn(\"cumulative_events\", F.count(\"*\").over(window))\n",
    "\n",
    "# Conversion rate by category\n",
    "conversion = events.groupBy(\"category_code\").agg(\n",
    "    F.sum(F.when(F.col(\"event_type\") == \"purchase\", 1).otherwise(0)).alias(\"purchase\"),\n",
    "    F.sum(F.when(F.col(\"event_type\") == \"view\", 1).otherwise(0)).alias(\"view\")\n",
    ").withColumn(\n",
    "    \"conversion_rate\",\n",
    "    (F.col(\"purchase\") / F.col(\"view\")) * 100\n",
    ")\n",
    "display(conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "915b6b5e-23f0-4728-9a8a-967d0a3146bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Derived feature: discounted price (10% off)\n",
    "events = events.withColumn(\n",
    "    \"discounted_price\",\n",
    "    F.col(\"price\") * 0.9\n",
    ")\n",
    "\n",
    "# Derived feature: is_high_price (True if price > 100)\n",
    "events = events.withColumn(\n",
    "    \"is_high_price\",\n",
    "    F.col(\"price\") > 100\n",
    ")\n",
    "\n",
    "display(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94b8ebe7-c02e-4166-9e95-84612d667a1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events.write.format(\"delta\").mode(\"overwrite\").save(\"/delta/events\")\n",
    "\n",
    "# Create managed table\n",
    "events.write.format(\"delta\").saveAsTable(\"events_table\")\n",
    "\n",
    "# SQL approach\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE events_delta\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM events_table\n",
    "\"\"\")\n",
    "\n",
    "# Test schema enforcement\n",
    "try:\n",
    "    wrong_schema = spark.createDataFrame([(\"a\",\"b\",\"c\")], [\"x\",\"y\",\"z\"])\n",
    "    wrong_schema.write.format(\"delta\").mode(\"append\").save(\"/delta/events\")\n",
    "except Exception as e:\n",
    "    print(f\"Schema enforcement: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f0b2ab6-d66c-46d1-b6ff-cb7beeca4353",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "events = spark.read.csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv\", header=True, inferSchema=True)\n",
    "\n",
    "events.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/ecommerce/delta/events\")\n",
    "\n",
    "# Create managed table\n",
    "events.write.format(\"delta\").saveAsTable(\"workspace.ecommerce.events_table\")\n",
    "\n",
    "# SQL approachworkspace.ecommerce.events_table\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE events_delta\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM workspace.ecommerce.events_table\n",
    "\"\"\")\n",
    "\n",
    "# Test schema enforcement\n",
    "try:\n",
    "    wrong_schema = spark.createDataFrame([(\"a\",\"b\",\"c\")], [\"x\",\"y\",\"z\"])\n",
    "    wrong_schema.write.format(\"delta\").mode(\"append\").save(\"/Volumes/workspace/ecommerce/delta/events\")\n",
    "except Exception as e:\n",
    "    print(f\"Schema enforcement: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "699554c9-01d1-4ec9-a0f7-9e65521c5570",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Create a managed volume in your schema\n",
    "CREATE VOLUME delta\n",
    "COMMENT 'Delta volume for ecommerce events'\n",
    "IN CATALOG workspace\n",
    "IN SCHEMA ecommerce;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a23900b-2e16-44ce-932e-60d4d95a423c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE VOLUME delta\n",
    "COMMENT 'Delta volume for ecommerce events'\n",
    "IN workspace.ecommerce;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbea4111-3fd1-4d56-b59e-b45a110bc663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE VOLUME workspace.ecommerce.delta\n",
    "COMMENT 'Delta volume for ecommerce events';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1358a0d8-b405-4589-81ea-869b72e31ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "events = spark.read.csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Nov.csv\", header=True, inferSchema=True)\n",
    "\n",
    "events.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/ecommerce/delta/events\")\n",
    "\n",
    "# Create managed table\n",
    "events.write.format(\"delta\").saveAsTable(\"workspace.ecommerce.events_table\")\n",
    "\n",
    "# SQL approachworkspace.ecommerce.events_table\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE events_delta\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM workspace.ecommerce.events_table\n",
    "\"\"\")\n",
    "\n",
    "# Test schema enforcement\n",
    "try:\n",
    "    wrong_schema = spark.createDataFrame([(\"a\",\"b\",\"c\")], [\"x\",\"y\",\"z\"])\n",
    "    wrong_schema.write.format(\"delta\").mode(\"append\").save(\"/Volumes/workspace/ecommerce/delta/events\")\n",
    "except Exception as e:\n",
    "    print(f\"Schema enforcement: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22e16b42-ccd5-4a9b-a38b-29a45c9330c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_path = \"/Volumes/workspace/ecommerce/delta/events\"\n",
    "csv_path = \"/Volumes/workspace/ecommerce/delta/new_data.csv\"\n",
    "\n",
    "# MERGE for incremental updates\n",
    "deltaTable = DeltaTable.forPath(spark, delta_path)\n",
    "updates = spark.read.csv(csv_path, header=True, inferSchema=True)\n",
    "\n",
    "deltaTable.alias(\"t\").merge(\n",
    "    updates.alias(\"s\"),\n",
    "    \"t.user_session = s.user_session AND t.event_time = s.event_time\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n",
    "\n",
    "# Time travel\n",
    "v0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)\n",
    "yesterday = spark.read.format(\"delta\") \\\n",
    "    .option(\"timestampAsOf\", \"2024-01-01\").load(delta_path)\n",
    "\n",
    "# Optimize\n",
    "spark.sql(\"OPTIMIZE workspace.ecommerce.events ZORDER BY (event_type, user_id)\")\n",
    "spark.sql(\"VACUUM workspace.ecommerce.events RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0056c5c6-7205-408f-9536-28a19a8d4e5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_path = \"/Volumes/workspace/ecommerce/delta/events\"\n",
    "csv_path = \"/Volumes/workspace/ecommerce/delta/new_data.csv\"  # Upload your CSV here\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, delta_path)\n",
    "updates = spark.read.csv(\n",
    "    csv_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "deltaTable.alias(\"t\").merge(\n",
    "    updates.alias(\"s\"),\n",
    "    \"t.user_session = s.user_session AND t.event_time = s.event_time\"\n",
    ").whenMatchedUpdateAll()\\\n",
    ".whenNotMatchedInsertAll()\\\n",
    ".execute()\n",
    "\n",
    "v0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)\n",
    "yesterday = spark.read.format(\"delta\")\\\n",
    "    .option(\"timestampAsOf\", \"2024-01-01\").load(delta_path)\n",
    "\n",
    "spark.sql(\"OPTIMIZE workspace.ecommerce.events ZORDER BY (event_type, user_id)\")\n",
    "spark.sql(\"VACUUM workspace.ecommerce.events RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f016b98-d1de-4ef1-991f-a3bc00db78f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/ecommerce/delta/events\")\n",
    "\n",
    "# Create managed table\n",
    "events.write.format(\"delta\").saveAsTable(\"workspace.ecommerce.csv_path\")\n",
    "\n",
    "# SQL approachworkspace.ecommerce.csv_path\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE events_csv\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM workspace.ecommerce.csv_path\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7083a7f6-e899-4212-b874-8501e5345f05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save Delta table to Unity Catalog volume\n",
    "events.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/ecommerce/delta/events\")\n",
    "\n",
    "# Create or replace managed table\n",
    "events.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.ecommerce.csv_path\")\n",
    "\n",
    "# SQL approach: create or replace table\n",
    "spark.sql(\"\"\"\n",
    "    CREATE OR REPLACE TABLE workspace.ecommerce.events_csv\n",
    "    USING DELTA\n",
    "    AS SELECT * FROM workspace.ecommerce.csv_path\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb320bc7-0b0a-443a-b4a4-6bf33322310d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_path = \"/Volumes/workspace/ecommerce/delta/events\"\n",
    "csv_path = \"/Volumes/workspace/ecommerce/delta/new_data.csv\"  # Upload your CSV here\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    PUT '/tmp/new_data.csv' INTO '/Volumes/workspace/ecommerce/delta/new_data.csv' OVERWRITE\n",
    "\"\"\")\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, delta_path)\n",
    "updates = spark.read.csv(\n",
    "    csv_path,\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "deltaTable.alias(\"t\").merge(\n",
    "    updates.alias(\"s\"),\n",
    "    \"t.user_session = s.user_session AND t.event_time = s.event_time\"\n",
    ").whenMatchedUpdateAll()\\\n",
    ".whenNotMatchedInsertAll()\\\n",
    ".execute()\n",
    "\n",
    "v0 = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_path)\n",
    "yesterday = spark.read.format(\"delta\")\\\n",
    "    .option(\"timestampAsOf\", \"2024-01-01\").load(delta_path)\n",
    "\n",
    "spark.sql(\"OPTIMIZE workspace.ecommerce.events ZORDER BY (event_type, user_id)\")\n",
    "spark.sql(\"VACUUM workspace.ecommerce.events RETAIN 168 HOURS\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5956398231899380,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
